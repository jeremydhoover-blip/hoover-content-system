# Rubric

## Pass criteria
All must be true:

- [ ] Sample size is stated for every finding
- [ ] Response rate and completion rate are reported
- [ ] Data quality limitations are explicitly acknowledged
- [ ] Percentages include base (n=X) for each statistic
- [ ] Findings include "so what" implications, not just numbers
- [ ] Scale questions report appropriate central tendency (mean or median)
- [ ] Significant segment differences are identified (if segments exist)
- [ ] Open-ended responses are coded with theme frequencies (if applicable)
- [ ] Recommendations trace to specific data points
- [ ] Comparative statements include statistical context (meaningful vs. noise)

## Fail criteria
Fail if any are true:

- [ ] Percentages reported without sample sizes
- [ ] Findings presented as precise when sample size is small (<30)
- [ ] Claims of "significant" difference without statistical basis
- [ ] Cherry-picked data that ignores contradictory findings
- [ ] No acknowledgment of non-response or selection bias
- [ ] Open-ended quotes selected without indication of frequency
- [ ] Recommendations not tied to data
- [ ] Missing response distributions for key questions
- [ ] Over-interpretation of single-question results

## Analysis quality checks

### Closed-ended questions
- [ ] Response distributions shown (not just means)
- [ ] Middle-of-scale responses interpreted (neutral vs. disengaged)
- [ ] Strongly agree/disagree distinguished from somewhat

### Scale questions
- [ ] Mean AND distribution shape reported
- [ ] Ceiling/floor effects noted if present
- [ ] Comparison to benchmark if available

### Open-ended questions
- [ ] Coding approach explained
- [ ] Theme frequency reported (not just cherry-picked quotes)
- [ ] Themes exhaustive (cover majority of responses)

### Segment analysis
- [ ] Segment sizes reported
- [ ] Differences are meaningful, not just numerical
- [ ] Multiple comparison risk acknowledged if many segments
