# Rubric

## Pass criteria
All must be true:

- [ ] Each opportunity is supported by evidence (research, data, feedback)
- [ ] Mapping dimensions are explicitly defined with criteria
- [ ] Dimensions are appropriate for the decision being made
- [ ] Scoring is consistent (same criteria applied to all opportunities)
- [ ] Map includes clear prioritization recommendations
- [ ] Recommendations include rationale tied to the map
- [ ] Number of opportunities is manageable (â‰¤20 per map)
- [ ] Quadrants or clusters are interpreted (not just shown)
- [ ] Evidence sources are cited

## Fail criteria
Fail if any are true:

- [ ] Opportunities are unsupported opinions ("we should have X")
- [ ] Dimensions are undefined or vague
- [ ] Dimensions don't differentiate (all opportunities cluster in one area)
- [ ] Scoring is inconsistent across opportunities
- [ ] Map is presented without interpretation or recommendation
- [ ] More than 25 opportunities on a single map (unactionable)
- [ ] Critical dependencies between opportunities are ignored
- [ ] Effort dimension conflates creation effort with maintenance effort

## Dimension quality checks
- [ ] Dimensions are independent (not measuring the same thing)
- [ ] Dimensions are relevant to the decision (would change priority order)
- [ ] Dimensions are scorable (clear criteria exist)
- [ ] Dimensions span the full range (opportunities distribute across quadrants)

## Recommendation quality checks
- [ ] Top priorities are explicitly stated (not just implied by map position)
- [ ] Recommendations acknowledge trade-offs
- [ ] Quick wins are identified if relevant
- [ ] Big bets are flagged with risk acknowledgment
- [ ] Deprioritized items have clear rationale
